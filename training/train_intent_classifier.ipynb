{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUiFyHvlEiLl",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%pip install awscli"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!aws configure"
      ],
      "metadata": {
        "id": "6utZaWK5VYk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!aws s3 cp s3://balldontlie/datasets/intent_classifier/v000/train.json /content/train.json"
      ],
      "metadata": {
        "collapsed": true,
        "id": "665uEDHoVdLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pandas numpy evaluate datasets transformers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GpmSarCxWl_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
      ],
      "metadata": {
        "id": "cgtCGHckW_Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/train.json\", \"r\") as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "df = pd.DataFrame(data[\"\"], columns=[\"query\", \"intent\"])\n",
        "df.to_csv(\"train.csv\", index=False)"
      ],
      "metadata": {
        "id": "ytNcPkC6XQ5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('csv', data_files=\"/content/train.csv\")\n",
        "train_test = dataset['train'].train_test_split(test_size=0.3, seed=27)\n",
        "test_val = train_test['test'].train_test_split(test_size=0.5, seed=27)\n",
        "\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': train_test['train'],\n",
        "    'validation': test_val['train'],\n",
        "    'test': test_val['test']\n",
        "})\n",
        "\n",
        "intent_labels = [\"lookup\", \"aggregation\", \"leaderboard\", \"comparison\", \"trend\", \"out_of_scope\"]\n",
        "id2label = {i: label for i, label in enumerate(intent_labels)}\n",
        "label2id = {label: i for i, label in enumerate(intent_labels)}"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WJfBaScuYKMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_labels(example):\n",
        "    example['labels'] = label2id[example['intent']]\n",
        "    return example\n",
        "\n",
        "dataset_dict = dataset_dict.map(encode_labels)"
      ],
      "metadata": {
        "id": "6_UXdLVniBce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def tokenize_function(examples):\n",
        "  return tokenizer(\n",
        "      examples['query'],\n",
        "      truncation=True,\n",
        "      padding=\"max_length\",\n",
        "      max_length=128\n",
        "  )\n",
        "\n",
        "tokenized_datasets = dataset_dict.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "woZUToQdZfLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    'distilbert-base-uncased',\n",
        "    num_labels=len(intent_labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")"
      ],
      "metadata": {
        "id": "9Ik8s2yKyiCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    logging_strategy='epoch',\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy'\n",
        ")\n",
        "\n",
        "accuracy = evaluate.load('accuracy')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  logits, labels = eval_pred\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "  return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "bnWGfyzFf7_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('./intent_classifier')"
      ],
      "metadata": {
        "id": "whAZQL5x3WLh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}